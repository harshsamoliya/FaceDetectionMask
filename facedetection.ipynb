{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facedetection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLOUi6Nh8JgmVfk2BeUkdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshsamoliya/FaceDetectionMask/blob/main/facedetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOFkS-QbkuG7"
      },
      "source": [
        "import numpy as np\r\n",
        "import random\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "\r\n",
        "dataDirectory = \"Directory\" ## training dataset\r\n",
        "classes = [\"WithMask\",\"WithOutMask\"] #list of classes\r\n",
        "\r\n",
        "# extracting the data\r\n",
        "# changing the image size() to 224*224 #\r\n",
        "img_size = 224\r\n",
        "training_data = []\r\n",
        "# making a function to extract data #\r\n",
        "def create_trainin_data():\r\n",
        "    for category in classes:\r\n",
        "        path = os.path.join(dataDirectory,category)\r\n",
        "        class_num = classes.index(category)     ## 0 1 , ##\r\n",
        "        for img in os.listdir(path):\r\n",
        "            try:\r\n",
        "                img_array = cv2.imread(os.path.join(path,img))\r\n",
        "                new_array = cv2.resize(img_array,(img_size,img_size))\r\n",
        "                training_data.append([new_array,class_num])\r\n",
        "            except Exception as e:\r\n",
        "                pass\r\n",
        "\r\n",
        "\r\n",
        "create_trainin_data()\r\n",
        "# suffling randomly\r\n",
        "random.shuffle(training_data)\r\n",
        "\r\n",
        "X = []\r\n",
        "y = []\r\n",
        "\r\n",
        "for feature,label in training_data:\r\n",
        "    X.append(feature)\r\n",
        "    y.append(label)\r\n",
        "\r\n",
        "X = np.array(X).reshape(-1,img_size,img_size,3)\r\n",
        "Y = np.array(y)\r\n",
        "# normalize the data\r\n",
        "x = X/255.0;\r\n",
        "\r\n",
        "# generalising data\r\n",
        "import pickle\r\n",
        "# for X:\r\n",
        "pickle_out = open(\"X.pickle\",\"wb\")\r\n",
        "pickle.dump(X,pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "# ................................\r\n",
        "# for Y:\r\n",
        "pickle_out = open(\"X.pickle\",\"wb\")\r\n",
        "pickle.dump(X,pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "\r\n",
        "# ........................importing Deep Learning Model ................#\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "model = tf.keras.applications.mobilenet.MobileNet() # model #\r\n",
        "\r\n",
        "base_input = model.layers[0].input\r\n",
        "base_output = model.layers[-4].output\r\n",
        "\r\n",
        "Flat_layer = layers.Flatten()(base_output)\r\n",
        "final_output = layers.Dense(1)(Flat_layer) ## 0 ,1 ##\r\n",
        "final_output = layers.Activation('sigmoid')(final_output)\r\n",
        "\r\n",
        "new_model = keras.Model(inputs = base_input,outputs =final_output)\r\n",
        "\r\n",
        "new_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\r\n",
        "new_model.fit(X,Y,epochs=1,validation_split=0.1)\r\n",
        "\r\n",
        "# checking the network the predictions for real faces\r\n",
        "frame = cv2.imread(\"12.jpg\")\r\n",
        "\r\n",
        "facecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
        "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
        "# Detection of faces in reactange from x->x+w and y->y+h\r\n",
        "faces  = facecascade.detectMultiScale(gray,1.1,4)\r\n",
        "for x,y,w,h in faces:\r\n",
        "    roi_gray = gray[y:y+h , x:x+w]\r\n",
        "    roi_color = frame[y:y+h , x:x+w]\r\n",
        "    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\r\n",
        "    faces = facecascade.detectMultiScale(roi_gray)\r\n",
        "    if len(faces) == 0:\r\n",
        "        print(\"face not Detected\")\r\n",
        "    else:\r\n",
        "        for (ex,ey,ew,eh) in faces:\r\n",
        "            face_roi = roi_color[ey:ey:eh,ex:ex+ew]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " # checking the image;\r\n",
        "final_image = cv2.resize(face_roi,(224,224))\r\n",
        "final_image = np.expand_dims(final_image,axis=0)\r\n",
        "final_image = final_image/255.0\r\n",
        "\r\n",
        "Predictions = new_model.predict(final_image)\r\n",
        "\r\n",
        "print(Predictions)\r\n",
        "\r\n",
        "# cool part -> checking with Laptop cam\r\n",
        "import cv2\r\n",
        "path  = \"haarcascade_frontalface_default.xml\"\r\n",
        "font_scale = 1.5\r\n",
        "font = cv2.FONT_HERSHEY_PLAIN\r\n",
        "\r\n",
        "# set the rectangle to default white\r\n",
        "recatangle_bgr = (255,255,255)\r\n",
        "# make a black image\r\n",
        "img = np.zeros((500,500))\r\n",
        "\r\n",
        "text = \"Some text in a box\"\r\n",
        "(text_width,text_height) = cv2.getTextSize(text,font,fontScale=font_scale,thickness=1)[0]\r\n",
        "# set  the start postion\r\n",
        "text_offset_x = 10\r\n",
        "text_offset_y = img.shape[0] - 25\r\n",
        "# box coordinate\r\n",
        "box_cords = ((text_offset_x,text_offset_y),(text_offset_x+text_width+2,text_offset_y-text_height-2))\r\n",
        "cv2.rectangle(img,box_cords[0],box_cords[1],recatangle_bgr,cv2.FILLED)\r\n",
        "cv2.putText(img,text,(text_offset_x,text_offset_y),font,fontScale=font_scale,color=(0,0,0),thickness=1)\r\n",
        "\r\n",
        "cap = cv2.VideoCapture(1)\r\n",
        "\r\n",
        "# check if camera is on or not\r\n",
        "if not cap.isOpened():\r\n",
        "    cap = cv2.VideoCapture(0)\r\n",
        "if not cap.isOpened():\r\n",
        "    raise IOError(\"cannot open webcam\")\r\n",
        "\r\n",
        "while True:\r\n",
        "    ret,frame = cap.read()\r\n",
        "    faceCasede  = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
        "    gray  = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "    faces = facecascade.detectMultiScale(gray,1.1,4)\r\n",
        "    for x,y,w,h in faces:\r\n",
        "        roi_gray = gray[y:y+h,x:x+w]\r\n",
        "        roi_color = frame[y:y + h, x:x + w]\r\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\r\n",
        "        if len(faces):\r\n",
        "            print(\"face not detected\")\r\n",
        "        else:\r\n",
        "            for (ex,ey,ew,eh) in faces:\r\n",
        "                face_roi = roi_color[ey:ey+eh,ex:ex+ew]\r\n",
        "\r\n",
        "    final_image = cv2.resize(face_roi,(244,244))\r\n",
        "    final_image = np.expand_dims(final_image,axis = 0 ) #   need for fouth dimension\r\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\r\n",
        "    Predictions = new_model.predict(final_image)\r\n",
        "\r\n",
        "    font_scale = 1.5\r\n",
        "    font = cv2.FONT_HERSHEY_COMPLEX\r\n",
        "\r\n",
        "    # now final work if prediction > 0 indicate there is no mask else there is mask\r\n",
        "    if (Predictions>0):\r\n",
        "        status = \"NO Mask\"\r\n",
        "\r\n",
        "        x1,y1,w1,h1 = 0,0,175,75\r\n",
        "\r\n",
        "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\r\n",
        "\r\n",
        "        cv2.putText(frame,status,(x1 + int(x1/10),y1 + int(y1/10)),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),2)\r\n",
        "\r\n",
        "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\r\n",
        "\r\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\r\n",
        "\r\n",
        "    else:\r\n",
        "\r\n",
        "        x1,y1,w1,h1 = 0,0,175,75\r\n",
        "\r\n",
        "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\r\n",
        "\r\n",
        "        cv2.putText(frame,status,(x1 + int(x1/10),y1 + int(y1/10)),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,255,0),2)\r\n",
        "\r\n",
        "        cv2.putText(frame,status,(100,150),font,3,(0,255,0),2,cv2.LINE_4)\r\n",
        "\r\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0))\r\n",
        "\r\n",
        "\r\n",
        "    cv2.imshow('Face Mask Detection Tutorial ',frame)\r\n",
        "\r\n",
        "    if cv2.waitKey(2) & 0xFF == ord('q'):\r\n",
        "        break\r\n",
        "\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}